{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!python -m pip install -U albumentations\n",
    "!python -m pip install opencv-python\n",
    "!python -m pip install tqdm\n",
    "!python -m pip install matplotlib\n",
    "\n",
    "%cd /content/drive/MyDrive/2022_2_machine_learning_hw2/tfdet_classification\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/2022_2_machine_learning_hw2/tfdet_classification')\n",
    "print(sys.path)\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lovewar_helper import place_data\n",
    "from tfdet.model.classifier import place_classifier\n",
    "import tensorflow as tf\n",
    "import tfdet\n",
    "import albumentations\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "backbone_type = \"resnet50\"\n",
    "use_pretrained_backbone = False\n",
    "use_augmentation = False\n",
    "learning_rate = 5e-5\n",
    "momentum = 0.9\n",
    "epochs = 100\n",
    "img_size = (512, 512, 3)\n",
    "img_wh = (512, 512)\n",
    "n_feature = 2048\n",
    "batch_size = 16\n",
    "\n",
    "output_name = 'p1_resnet50_pretrained_x'\n",
    "tr_img_root = \"/content/drive/MyDrive/2022_2_machine_learning_hw2/love_war_place/train\"\n",
    "te_img_root = \"/content/drive/MyDrive/2022_2_machine_learning_hw2/love_war_place/val\"\n",
    "\n",
    "class_dict = {\n",
    "    \"car\": 0,\n",
    "    \"front_of_buliding\": 1,\n",
    "    \"hospital\": 2,\n",
    "    \"house\": 3,\n",
    "    \"indoor\": 4,\n",
    "    \"restaurant\": 5,\n",
    "    \"rooftop\": 6,\n",
    "    \"street\": 7\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "1. albumentations\n",
    "https://github.com/albumentations-team/albumentations(https://albumentations.ai/docs/getting_started/image_augmentation/)\n",
    "\n",
    "2. albumentations docs\n",
    "https://albumentations.ai/docs/api_reference/augmentations/\n",
    "\n",
    "3. recommend\n",
    "albumentations.RandomBrightness / albumentations.RandomContrast / albumentations.ChannelShuffle /\n",
    "albumentations.RandomCrop / albumentations.HorizontalFlip / albumentations.Rotate /\n",
    "etc\n",
    "'''\n",
    "def augment_train_data(train_ds, image_size, label_cnt, batch_size, shuffle=True):\n",
    "    transforms = albumentations.Compose([\n",
    "        albumentations.Normalize(),\n",
    "        albumentations.Resize(image_size[0], image_size[1]),\n",
    "        albumentations.RandomBrightness(0.2, p=0.5),\n",
    "        albumentations.RandomContrast(0.2, p=0.5),\n",
    "        albumentations.ChannelShuffle(p=0.5)\n",
    "    ])\n",
    "\n",
    "    def aug_fn(image):\n",
    "        data = {\"image\": image}\n",
    "        aug_data = transforms(**data)\n",
    "        aug_img = aug_data[\"image\"]\n",
    "        aug_img = tf.cast(aug_img, tf.float32)\n",
    "        return aug_img\n",
    "\n",
    "    def process_data(image, label):\n",
    "        aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "        return aug_img, label\n",
    "\n",
    "    def set_shapes(img, label, img_shape=image_size, label_count=label_cnt):\n",
    "        img.set_shape(img_shape)\n",
    "        label.set_shape(label_count)\n",
    "        return img, label\n",
    "\n",
    "    ds_alb = train_ds.map(partial(process_data), num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    ds_alb = ds_alb.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # ds_alb = ds_alb.repeat()\n",
    "    if shuffle:\n",
    "        ds_alb = ds_alb.shuffle(buffer_size=batch_size * 10)\n",
    "    ds_alb = ds_alb.batch(batch_size)\n",
    "    return ds_alb\n",
    "\n",
    "\n",
    "def preprocess_train_data(train_ds, image_size, label_cnt, batch_size, shuffle=True):\n",
    "    transforms = albumentations.Compose([\n",
    "        albumentations.Normalize(),\n",
    "        albumentations.Resize(image_size[0], image_size[1]),\n",
    "    ])\n",
    "\n",
    "    def aug_fn(image):\n",
    "        data = {\"image\": image}\n",
    "        aug_data = transforms(**data)\n",
    "        aug_img = aug_data[\"image\"]\n",
    "        aug_img = tf.cast(aug_img, tf.float32)\n",
    "        return aug_img\n",
    "\n",
    "    def process_data(image, label):\n",
    "        aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "        return aug_img, label\n",
    "\n",
    "    def set_shapes(img, label, img_shape=image_size, label_count=label_cnt):\n",
    "        img.set_shape(img_shape)\n",
    "        label.set_shape(label_count)\n",
    "        return img, label\n",
    "\n",
    "    ds_alb = train_ds.map(partial(process_data), num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    ds_alb = ds_alb.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # ds_alb = ds_alb.repeat()\n",
    "    if shuffle:\n",
    "        ds_alb = ds_alb.shuffle(buffer_size=batch_size * 10)\n",
    "    ds_alb = ds_alb.batch(batch_size)\n",
    "    return ds_alb\n",
    "\n",
    "\n",
    "def preprocess_val_data(val_ds, image_size, label_cnt, batch_size):\n",
    "    transforms = albumentations.Compose([\n",
    "        albumentations.Normalize(),\n",
    "        albumentations.Resize(image_size[0], image_size[1]),\n",
    "    ])\n",
    "\n",
    "    def aug_fn(image):\n",
    "        data = {\"image\": image}\n",
    "        aug_data = transforms(**data)\n",
    "        aug_img = aug_data[\"image\"]\n",
    "        aug_img = tf.cast(aug_img, tf.float32)\n",
    "        return aug_img\n",
    "\n",
    "    def process_data(image, label):\n",
    "        aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
    "        return aug_img, label\n",
    "\n",
    "    def set_shapes(img, label, img_shape=image_size, label_count=label_cnt):\n",
    "        img.set_shape(img_shape)\n",
    "        label.set_shape(label_count)\n",
    "        return img, label\n",
    "\n",
    "    ds_alb = val_ds.map(partial(process_data), num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    ds_alb = ds_alb.map(set_shapes, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size)\n",
    "    return ds_alb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    tr_img, tr_class = place_data.parse_file_path(tr_img_root, class_dict)\n",
    "    te_img, te_class = place_data.parse_file_path(te_img_root, class_dict)\n",
    "\n",
    "    training_data = tf.data.Dataset.from_tensor_slices((tr_img, tr_class))\n",
    "    validation_data = tf.data.Dataset.from_tensor_slices((te_img, te_class))\n",
    "\n",
    "    training_data = training_data.map(place_data.load_image_and_label_from_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    validation_data = validation_data.map(place_data.load_image_and_label_from_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if use_augmentation:\n",
    "        training_data = augment_train_data(training_data, image_size=img_size, label_cnt=len(class_dict.keys()),\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    else:\n",
    "        training_data = preprocess_train_data(training_data, image_size=img_size, label_cnt=len(class_dict.keys()),\n",
    "                                              batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    validation_data = preprocess_val_data(validation_data, image_size=img_size, label_cnt=len(class_dict.keys()),\n",
    "                                          batch_size=batch_size)\n",
    "\n",
    "    if use_pretrained_backbone:\n",
    "        weights = \"imagenet\"\n",
    "\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    x = tf.keras.layers.Input(shape=img_size)\n",
    "\n",
    "    if backbone_type == \"resnet50\":\n",
    "        feature = tfdet.model.backbone.resnet50(x, weights=weights)[-1]\n",
    "\n",
    "    elif backbone_type == \"resent101\":\n",
    "        feature = tfdet.model.backbone.resnet101(x, weights=weights)[-1]\n",
    "\n",
    "    elif backbone_type == \"vgg16\":\n",
    "        feature = tfdet.model.backbone.vgg16(x, weights=weights)[-1]\n",
    "\n",
    "    elif backbone_type == \"mobilenet\":\n",
    "        feature = tfdet.model.backbone.mobilenet(x, weights=weights)[-1]\n",
    "\n",
    "    else:\n",
    "        # default : resnet50\n",
    "        feature = tfdet.model.backbone.resnet50(x, weights=weights)[-1]\n",
    "\n",
    "    out = place_classifier.Classifier(n_class=len(class_dict), n_feature=n_feature)(feature)\n",
    "    model = tf.keras.Model(inputs=x, outputs=out)\n",
    "    model.summary()\n",
    "\n",
    "    os.makedirs(\"logs/{}/\".format(output_name), exist_ok=True)\n",
    "    os.makedirs(\"weight/{}/\".format(output_name), exist_ok=True)\n",
    "\n",
    "    logdir = \"logs/{}/\".format(output_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weight/{}/best_place_model.h5\".format(output_name),\n",
    "                                                    monitor='val_accuracy', verbose=1,\n",
    "                                                    save_best_only=True, save_weights_only=True, mode='max', period=1)\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    model.fit(training_data, validation_data=validation_data, epochs=epochs, callbacks=[tensorboard_callback, checkpoint])\n",
    "    model.save_weights(\"weight/{}/place_model.h5\".format(output_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}